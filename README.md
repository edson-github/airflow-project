# Projeto de Aprendizado em Engenharia de Dados com Airflow

Este projeto Ã© um ambiente de aprendizado para engenharia de dados utilizando o Apache Airflow. O objetivo Ã© fornecer uma estrutura bÃ¡sica para entender os conceitos fundamentais de orquestraÃ§Ã£o de pipelines de dados.

## ğŸš€ VisÃ£o Geral

O projeto demonstra como:
- Configurar um ambiente local do Airflow com Docker Compose
- Criar DAGs (Directed Acyclic Graphs) para orquestraÃ§Ã£o de tarefas
- Implementar operadores bÃ¡sicos do Airflow
- Gerenciar dependÃªncias entre tarefas
- Monitorar execuÃ§Ãµes de pipelines

## ğŸ“‹ PrÃ©-requisitos

- Python 3.8+
- Docker e Docker Compose
- Git

## âš ï¸ Notas Importantes Antes de Rodar

1. **InicializaÃ§Ã£o do Banco de Dados do Airflow**

   Antes de iniciar os containers, Ã© necessÃ¡rio rodar o comando abaixo para inicializar o banco de dados do Airflow:

   ```bash
   docker compose run --rm webserver airflow db migrate
   ```

2. **Chave Fernet**

   Certifique-se de que a variÃ¡vel `AIRFLOW__CORE__FERNET_KEY` estÃ¡ definida corretamente no `.env` ou no `docker-compose.yml`, com uma chave vÃ¡lida de 32 bytes codificada em base64. VocÃª pode gerar uma chave com o seguinte comando Python:

   ```python
   from cryptography.fernet import Fernet
   print(Fernet.generate_key().decode())
   ```

3. **CriaÃ§Ã£o de UsuÃ¡rio Admin**

   ApÃ³s a inicializaÃ§Ã£o do banco, crie um usuÃ¡rio para acesso Ã  interface web:

   ```bash
   docker compose run --rm webserver airflow users create \
     --username admin \
     --firstname Admin \
     --lastname User \
     --role Admin \
     --email admin@example.com \
     --password admin
   ```

## ğŸ› ï¸ InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone [URL_DO_REPOSITÃ“RIO]
cd airflow-project
```

2. Inicie o ambiente Airflow usando Docker Compose:
```bash
docker compose up -d
```

3. Acesse a interface web do Airflow:
```
http://localhost:8080
```
- UsuÃ¡rio: admin
- Senha: admin

## ğŸ“ Estrutura do Projeto

```
airflow-project/
â”œâ”€â”€ dags/                    # DiretÃ³rio para suas DAGs
â”œâ”€â”€ plugins/                 # Plugins personalizados
â”œâ”€â”€ data/                    # Dados de exemplo
â”œâ”€â”€ docker-compose.yml       # ConfiguraÃ§Ã£o do Docker
â”œâ”€â”€ .env                     # VariÃ¡veis de ambiente, incluindo a Fernet Key
â””â”€â”€ README.md                # Este arquivo
```

## ğŸ“š Exemplos IncluÃ­dos

O projeto inclui exemplos de DAGs para:
- ExtraÃ§Ã£o de dados de APIs
- TransformaÃ§Ã£o de dados
- Carregamento em banco de dados
- Agendamento de tarefas
- Tratamento de erros

## ğŸ¯ Objetivos de Aprendizado

- Entender os conceitos bÃ¡sicos do Airflow
- Aprender a criar e gerenciar DAGs
- Compreender a execuÃ§Ã£o de tarefas em paralelo
- Implementar boas prÃ¡ticas de engenharia de dados
- Monitorar e depurar pipelines

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para:
- Reportar bugs
- Sugerir melhorias
- Adicionar novos exemplos
- Compartilhar conhecimento

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## ğŸ“ Suporte

Para dÃºvidas ou sugestÃµes, abra uma issue no repositÃ³rio.
```

---

Se quiser, posso te ajudar a atualizar o arquivo no repositÃ³rio diretamente (via terminal ou GitHub). Deseja que eu tambÃ©m atualize o `.env.example` com a variÃ¡vel `FERNET_KEY` e outras sugestÃµes.